2020-07-19 07:51am ET

Primary vs. derived.
Remembering why I turned off Thunderbird "Gloda" (Global Search Database)
https://support.mozilla.org/en-US/kb/global-search

Because it was a multi-gigabyte index file that kept changing
and which Mac TimeMachine kept backing up each time....
Causing long delays and bloating backups and chewing up backup drive disk space.

I am often thinking (and constrained) by concern of how to make Twirlip/Pointrel archives
easy to backup incrementally. Challenging as hard to have changing indexes then...
Of course, you can selectively exclude files from backups.
And maybe that is the answer?
To exclude backing up big files that are derived -- tradeoff of storage vs. time.

In rough calculations, on Lenovo flex14 laptop, 
Thunderbird is indexing about 50 messages per second.
Thunderbird is adding (initially) about 10K (20K?) per message to global-messages-db.sqlite.
It seems it will take about five hours to index a million messages.
It will end up with a ~10GB index file.
The "Activity Manager" explains what is going on.
It says how many emails have been indexed of how many total and how long it took.

So, is that acceptable? Interesting how people must think it is.

[In the end, the resulting index file is just under 4.1 GB.
It took about 8.5 hours including indexing RSS feeds of 100ks of tweets.
For some reason one rss feed at the end took 30 minutes to index ~100K messages
-- maybe the laptop was sleeping?
It was unfortunate I could not copy and paste from the Activity Manager window.]

Laptop getting warm as it runs the indexing process... 
Thunderbird running at 7% CPU load.
~20% load overall. Maybe one full vcpu thread of eight?
How much heat from flash drive itself?

Later, about 110K messages indexed so far in about 33 minutes and about 450MB.
So, about 55 messages a second, and about 4K per message of indexing.
Maybe my Sent messages where is started are longer than average. :-)

Ideally Linux would have some way of labelling derived files 
or putting them in a special folder (under /var?) that is not backed up.

Until then: https://linuxize.com/post/how-to-exclude-files-and-directories-with-rsync/
$ rsync -a --exclude 'file.txt' src_directory/ dst_directory/
$ rsync -a --exclude '*.jpg*' src_directory/ dst_directory/
$ rsync -a --exclude={'file1.txt','dir1/*','dir2'} src_directory/ dst_directory/
$ rsync -a --exclude-from='exclude-file.txt' src_directory/ dst_directory/
Where exclude-file.txt is:
file1.txt
dir1/*
dir2

Maybe I need to accept there will be a large index file somewhere which is derived
and which optionally will not be backed up?
Although five house (in this case) is a long time to wait until something is operational again.
What if it was ten million messages or a billion messages?

----

Have been thinking recently about storage similar to TimeMachine and such like so:
Directories for each time period (week, day, hour, minute, whatever).
Subdirectories reflecting a hierarchy of "streams" (which can be whatever -- discussions, text files, images, etc.)
A stream can have substreams (/somewhere/mystream/mysubstream-a,b,c).
Each stream is one file with incremental transactions.
A stream could also be a directory with one transaction per file, but too much overhead of file system?
To find everything in a stream, you move across multiple time top-level directories,
and you collect all the transactions related to that stream.

Where is the index for a stream (or hierarchy of streams?).
If could be in a separate index directory parallelling all the streams.
But if you have a global stream directory with everything -- so you need oen per stream?
So could maybe just have one big index file?

That index file is perhaps not backed up as it is derived...
But is would take a long time to rebuild.
Would be nice if could backup index file incrementally too.
The CouchDB approach to a growing index with the end referring to immutable beginning?
But done as segments of the index in different files?
Maybe work in progress index segment and then permanent segments?
Nice idea but too much for now? Distraction from UI and apps.

---

So just use one big SQLite file?
And have SQL API to use it by the client to the server?

Alternative is a triplestore index approach (with or without SQLite) with a triples API.

Or could use CouchDB and have a document store of transactions...

SQL API to sqlite files is more general?
Then can open any SQLite file on the server.

---

The reason for some index is to support Twirlip apps making sense of data on rest of disk.

---

Looking at sqlite wrappers, it seems like sqlite has about 80 API functions that need to be wrapped.
http://spiderape.sourceforge.net/plugins/sqlite/

That gives me pause. Maybe easier to just use Pointrel API with a few API functions
like addTriple (or addTransaction) and findTriple? And maybe a few others.
ALso sqlite requires (for efficiency) a connection and a cursor.
Maybe no way around cursor? Unless use original Pointrel approach of linked list of same field?
Then a cursor is just a pointer to the file position of the last triple returned.

2022-06-21 9:27pm ET

Comparing ideas for raw storage of triples -- simplicity vs. expandability (where only last field can have spaces -- or maybe unescaped spaces):

    {"a":"collageNode:1270111357464769636","b":"modificationDate","c":"date:2013-01-06T09:33:20.986Z"}

    collageNode:1270111357464769636 modificationDate date:2013-01-06T09:33:20.986Z

    replace collageNode:1270111357464769636 modificationDate date:2013-01-06T09:33:20.986Z

2022-06-22 8:30am ET

Or can include a version field at start for upgrades (including json):

    v1 replace collageNode:1270111357464769636 modificationDate date:2013-01-06T09:33:20.986Z

    v2 2013-01-06T09:33:20.986Z al.selvin@example.com replace collageNode:1270111357464769636 modificationDate date:2013-01-06T09:33:20.986Z

Thinking on how I like the content-type in the last field. 
And in the first for the class of a uuid.

But I don't like how application code gets littered with error-prone string manipulation like:
    t.addTripleABC(uuid, "label", "text:" + newLabel)

Might be more explicit to have:

    t.addTripleABTC(uuid, "label", "text", newLabel)

Or:

    t.addTripleABCT(uuid, "label", newLabel, "text")

Where the last field defaults to "text" if not specified.

And maybe then find(a, b, c) functions with and without type for return result or with auto-conversion?

I'm OK with the first UUID field being always of that form,
although it would be good to hav a uuid function like:

    const uuid = makeUUID("collageNode")

instead of:

    const uuid = "collageNode:" + UUID.uuidv4()
    
Although one could argue that a type is superfluous if have a type implicit in the B field:

    collageNode:1270111357464769636 modificationDate date:2013-01-06T09:33:20.986Z

Versus:

    collageNode:1270111357464769636 modificationDate 2013-01-06T09:33:20.986Z

But I do like the consistency of every C field having a type, even if just a handful
of text, json, number, date, or some class. 

I handled that partially before by automatically converting to and from JSON.

But JSON does not have dates.
But they could be strings the application converts -- or even leaves as strings.

(Idea of having one sentence per line in electronic documents?
No extra cost for files -- but more scrolling.
But maybe easier to read conceptually?)

It feels a little odd to not have a type for the B field, even as it is simpler and maybe not needed.
I see the argument for XML-like namespacing though.
But you can either add or nto add a type or namespace yourself:

    collageNode:1270111357464769636 myApp:modificationDate date:2013-01-06T09:33:20.986Z

Or even:

    v1 myApp/collageNode:1270111357464769636 myApp/field:modificationDate myApp/date:2013-01-06T09:33:20.986Z

One risk is that once you start using text fields of some sort you get stuck --
in the sense that it is not easy to change those names in the stored files.
In a database, you could do some sort fo system-wide upgrade perhaps.
Fundamental limitation of these sorts of text fields.

I know in past though that I did not like have six required fields to add things:

    addTripleTATBTC("myApp/collageNode", "1270111357464769636", "myApp/field", "modificationDate", "myApp/date", "2013-01-06T09:33:20.986Z")

Realizing having six things exceeds easy mental capacity of three or four things in memory.

From: https://en.wikipedia.org/wiki/XML_namespace
> Attributes are never subject to the default namespace.
> An attribute without an explicit namespace prefix is considered not to be in any namespace.

XML Elements may be in a default namespace though after defining one.

What of not using a colon?

    v3 myApp/collageNode/1270111357464769636 myApp/field/modificationDate myApp/date/2013-01-06T09:33:20.986Z

Or pipe?

    v3 myApp|collageNode|1270111357464769636 myApp|field|modificationDate myApp|date|2013-01-06T09:33:20.986Z

Where pipes would have to be escaped if in text?
    
    v3 myApp|collageNode|1270111357464769636 myApp|field|detail myApp|text|Some text with a pipe next \| that needs to be escaped.

Although the leaning-forward slash (/) is so common as a separator for levels.
Is it more standard to use it or is it confusing where will get munged by other code?
And where slash will need to be escaped in every path stored in a text field?

The colon is also potentially conflicting with JSON fields or URLs.

The colon for type also conflicts conceptually with JSON where the colon is used with a field name not a type.

Related: https://stackoverflow.com/questions/492090/least-used-delimiter-character-in-normal-text-ascii-128

Could use unit separator instead of space?

  https://unicode-table.com/en/001F/

Let's see what a "unit separator" looks like here: 

A small empty box. Seems confusing...

And hard to type for manual editing.

Let's see:

    v4 myApp|collageNode|1270111357464769636myApp|field|detailmyApp|text|Some text with a pipe next \| that needs to be escaped.

Not impossible though.

But then would be issue if try to use other separators and they are also boxes.

Could also do:

    v5 myAppcollageNode1270111357464769636 myAppfielddetail myApptextSome text with a pipe next \| that needs to be escaped.

Again, maybe confusing and hard to type or read.

I kind of like the forward slash the best as a "path".
But I worry it will be harder to read escaped:

    v6 myApp/collageNode/1270111357464769636 myApp/field/URL myApp/URL/https:\/\/simon.buckinghamshum.net\/2015\/11\/al-selvin-memories-tributes\/

I guess it is not that bad...

But contrast with pipes:

    v6 myApp|collageNode|1270111357464769636 myApp|field|URL myApp|URL|https://simon.buckinghamshum.net/2015/11/al-selvin-memories-tributes/

For the common case.

-----

Thinking that of use the pipe then can use UUIDs as file names if do object storage.
I liked that idea in Twirlip7 even if it was not clear what the pool of objects would be.
But "myApp|collageNode|1270111357464769636" can be a file name by itself.
In Twirlip7 did the sha256 hash of those instead though.

On the other hand, with slashes, could just make subdirectories...

But get a sense this is all fun and interesting to think about but also kind of arbitrary.
Whatever way I choose, I will need to escape some characters -- at the least newlines
if want one triple per line.
Otherwise would need an end character or symbol which would need to be escaped
or chosen everytime so does nor appear in the text.
I did that before too.

Right now thigns are in JSON, so the question is, what is the benefit of switching?
Less computer cycles to parse?
Easier for humans to read?
More expandable with (escaped) pipes to have hierarchy of namespaces (or none at all)?
Maybe harder to parse with escaped pipes? Harder to break into chunks?
Or just limit number of splits?

Not sure how to split on pipes if some are escaped and no split on escaped pipes?

Ideas on splitting:
https://stackoverflow.com/questions/34045019/split-string-by-comma-but-not-escaped-in-javascript

But anything coded by hand unlikely to be as fast as built-in JSON parsing.

====

2022-07-21

Ways to name files when you have a lot of things
and where manually naming a file for each item is impractical or undesired:

* Hash of content
* Sequence numbers as add each file
* Timestamp when adding file
* UUID from content (but may not be unique)
* Random number
* A mix of the above

Assuming probably using with nested directories with parts of name.

Can also add some extra sharding unique info 
like author or archive uuid or machine/process uuid.

Examples: emails, chat messages, downloaded web pages or parsed parts, JSON objects,
pictures, screenshots, recordings, imported files for an archiver, file versions.

====

2022-07-23

Most important is idea of shared standards, not implementation (which can be replaced).
Emphasizing standards -- such as they were in 1991 -- is what the web got right.

Dojo notion of a "Store" from original Dojo and dgrid.
Reflected in idea of "Notebook" from Twirlip7.

----

Idea of successive refinement of data through multiple versions 
and additions and deletions and connections.
Supporting organic growth of data but also pruning and reshaping.
And also "time travel" to revisit past data organization.
When the past is secure and revisitable, can move forward with confidence.
Idea of "undo" or "history" so people can explore and create with confidence.
